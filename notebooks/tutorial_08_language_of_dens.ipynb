{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 8: The Language of Dens\n",
    "## Language as a Category\n",
    "\n",
    "---\n",
    "\n",
    "### The Linguistic Turn\n",
    "\n",
    "*To the research assistant:*\n",
    "\n",
    "*In Year 899, Tessery Vold turned her relational framework toward an unexpected domain: language itself.*\n",
    "\n",
    "*Vold observed that words and phrases form a natural category. Objects are linguistic expressions—words, phrases, sentences. Morphisms are containment relationships: \"stakdur\" is contained in \"the stakdur,\" which is contained in \"the stakdur hunts.\"*\n",
    "\n",
    "*This seemingly simple observation has profound implications. If language is a category, then linguistic meaning can be understood categorically. A word's meaning is not an intrinsic property—it is determined by how the word relates to other words. This is Vold's Probing Theorem applied to language.*\n",
    "\n",
    "*The Capital linguists dismissed this as reductionist. How can meaning arise from mere containment? But Vold countered: \"You know a word by the company it keeps. This is not metaphor. This is mathematics.\"*\n",
    "\n",
    "*Your task: Analyze linguistic containment data to understand the categorical structure of Densworld language. Determine whether meaning can indeed be captured by containment relationships.*\n",
    "\n",
    "—*Archive Review Committee, Year 934*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## What You Will Learn\n",
    "\n",
    "In this tutorial, you will learn to:\n",
    "\n",
    "1. Model **language as a category** with words as objects and containment as morphisms\n",
    "2. Understand **substring relations** and their categorical properties\n",
    "3. Build **phrase graphs** representing linguistic structure\n",
    "4. Connect linguistic categories to **distributional semantics**\n",
    "5. See how this relates to modern NLP and language models\n",
    "\n",
    "By the end, you will understand:\n",
    "- Why language has natural categorical structure\n",
    "- How \"meaning is use\" connects to the Yoneda perspective\n",
    "- The foundation of word embeddings in categorical terms\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## The Language Category\n",
    "\n",
    "Consider language as a category **L**:\n",
    "\n",
    "- **Objects**: Strings (words, phrases, sentences)\n",
    "- **Morphisms**: Containment relations\n",
    "  - There is a morphism s → t if s is a substring of t\n",
    "  - Or more generally: s appears in the context of t\n",
    "- **Identity**: Every string contains itself\n",
    "- **Composition**: If s ⊆ t and t ⊆ u, then s ⊆ u\n",
    "\n",
    "This is a **pre-order category**—there is at most one morphism between any two objects.\n",
    "\n",
    "### Vold's Interpretation\n",
    "\n",
    "> *\"The word 'stakdur' means nothing in isolation. But place it in contexts: 'the stakdur,' 'stakdur territory,' 'the stakdur hunts'—and meaning emerges. The word is defined by what contains it.\"*\n",
    "> — Tessery Vold, \"The Language of Dens,\" Year 899\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Part 1: Loading Linguistic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('deep')\n",
    "\n",
    "print(\"Libraries loaded. Ready to study the Language of Dens.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load linguistic containment data\n",
    "BASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/densworld-datasets/main/data/\"\n",
    "\n",
    "containment = pd.read_csv(BASE_URL + \"linguistic_containment.csv\")\n",
    "\n",
    "print(f\"Linguistic containment records: {len(containment)}\")\n",
    "print(f\"\\nColumns: {list(containment.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# View sample data\n",
    "containment.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-7",
   "metadata": {},
   "source": [
    "Each row represents a **morphism** in the language category:\n",
    "- `shorter_phrase` → `longer_phrase` (containment)\n",
    "- `containment_type`: How the phrase is extended (prefix, compound, modifier, etc.)\n",
    "- `frequency_score`: How often this containment appears in the corpus\n",
    "- `context_probability`: Probability of the longer phrase given the shorter\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Part 2: Building the Language Category\n",
    "\n",
    "Let's construct the category from the containment data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract all phrases (objects in the category)\n",
    "shorter_phrases = set(containment['shorter_phrase'])\n",
    "longer_phrases = set(containment['longer_phrase'])\n",
    "all_phrases = shorter_phrases | longer_phrases\n",
    "\n",
    "print(f\"Shorter phrases: {len(shorter_phrases)}\")\n",
    "print(f\"Longer phrases: {len(longer_phrases)}\")\n",
    "print(f\"Total unique phrases (objects): {len(all_phrases)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the containment graph (morphisms)\n",
    "G_lang = nx.DiGraph()\n",
    "\n",
    "# Add nodes\n",
    "G_lang.add_nodes_from(all_phrases)\n",
    "\n",
    "# Add edges (morphisms): shorter → longer\n",
    "for _, row in containment.iterrows():\n",
    "    G_lang.add_edge(\n",
    "        row['shorter_phrase'], \n",
    "        row['longer_phrase'],\n",
    "        containment_type=row['containment_type'],\n",
    "        frequency=row['frequency_score'],\n",
    "        probability=row['context_probability']\n",
    "    )\n",
    "\n",
    "print(f\"Language category constructed:\")\n",
    "print(f\"  Objects (phrases): {G_lang.number_of_nodes()}\")\n",
    "print(f\"  Morphisms (containments): {G_lang.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify pre-order property: at most one morphism between any pair\n",
    "edge_counts = defaultdict(int)\n",
    "for u, v in G_lang.edges():\n",
    "    edge_counts[(u, v)] += 1\n",
    "\n",
    "multi_edges = [(k, v) for k, v in edge_counts.items() if v > 1]\n",
    "\n",
    "if multi_edges:\n",
    "    print(f\"Warning: {len(multi_edges)} pairs have multiple edges\")\n",
    "else:\n",
    "    print(\"Pre-order verified: at most one morphism between any pair\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 3: Analyzing Containment Structure\n",
    "\n",
    "Let's explore how words relate to their contexts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For each word, find all phrases that contain it\n",
    "def get_containing_phrases(word, G):\n",
    "    \"\"\"Get all phrases that contain the given word (morphisms from word).\"\"\"\n",
    "    return list(G.successors(word))\n",
    "\n",
    "# Analyze key words\n",
    "key_words = ['stakdur', 'passage', 'form', 'archive', 'morphism']\n",
    "\n",
    "print(\"Containing phrases for key words:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for word in key_words:\n",
    "    if word in G_lang:\n",
    "        containers = get_containing_phrases(word, G_lang)\n",
    "        print(f\"\\n'{word}' is contained in {len(containers)} phrases:\")\n",
    "        for phrase in containers[:5]:\n",
    "            print(f\"    → '{phrase}'\")\n",
    "        if len(containers) > 5:\n",
    "            print(f\"    ... and {len(containers) - 5} more\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Containment type distribution\n",
    "type_counts = containment['containment_type'].value_counts()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(12, 5))\n",
    "type_counts.plot(kind='barh', ax=ax, color='steelblue', alpha=0.7)\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_ylabel('Containment Type')\n",
    "ax.set_title('Distribution of Containment Types in the Language Category')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-15",
   "metadata": {},
   "source": [
    "Different containment types reveal how language builds structure:\n",
    "- **compound_formation**: \"passage\" → \"passage diagram\"\n",
    "- **modifier_prefix**: \"stakdur\" → \"apex stakdur\"\n",
    "- **prefix_context**: \"stakdur\" → \"the stakdur\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-16",
   "metadata": {},
   "source": [
    "## Part 4: The Yoneda Perspective on Language\n",
    "\n",
    "Applying the Probing Theorem: a word is determined by what contains it.\n",
    "\n",
    "Hom(word, -) = {phrases that contain word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def language_embedding(word, G, containment_df):\n",
    "    \"\"\"\n",
    "    Build a 'contextual embedding' for a word based on what contains it.\n",
    "    Returns: (container_phrases, containment_types, probabilities)\n",
    "    \"\"\"\n",
    "    if word not in G:\n",
    "        return [], [], []\n",
    "    \n",
    "    containers = []\n",
    "    types = []\n",
    "    probs = []\n",
    "    \n",
    "    for _, row in containment_df[containment_df['shorter_phrase'] == word].iterrows():\n",
    "        containers.append(row['longer_phrase'])\n",
    "        types.append(row['containment_type'])\n",
    "        probs.append(row['context_probability'])\n",
    "    \n",
    "    return containers, types, probs\n",
    "\n",
    "# Compare embeddings for different words\n",
    "words_to_compare = ['stakdur', 'grimslew', 'passage', 'form']\n",
    "\n",
    "print(\"Language embeddings (what contains each word):\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for word in words_to_compare:\n",
    "    containers, types, probs = language_embedding(word, G_lang, containment)\n",
    "    print(f\"\\n'{word}':\")\n",
    "    for c, t, p in zip(containers[:4], types[:4], probs[:4]):\n",
    "        print(f\"    → '{c}' ({t}, p={p:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build feature vectors for words based on containment types\n",
    "# This is analogous to word2vec but using categorical structure\n",
    "\n",
    "all_types = list(containment['containment_type'].unique())\n",
    "words_with_contexts = list(shorter_phrases)\n",
    "\n",
    "# Feature matrix: rows = words, columns = containment types\n",
    "# Value = average probability for that type\n",
    "n_words = len(words_with_contexts)\n",
    "n_types = len(all_types)\n",
    "\n",
    "feature_matrix = np.zeros((n_words, n_types))\n",
    "\n",
    "for i, word in enumerate(words_with_contexts):\n",
    "    word_data = containment[containment['shorter_phrase'] == word]\n",
    "    for j, ctype in enumerate(all_types):\n",
    "        type_data = word_data[word_data['containment_type'] == ctype]\n",
    "        if len(type_data) > 0:\n",
    "            feature_matrix[i, j] = type_data['context_probability'].mean()\n",
    "\n",
    "print(f\"Language embedding matrix: {feature_matrix.shape}\")\n",
    "print(f\"  Rows (words): {n_words}\")\n",
    "print(f\"  Columns (containment types): {n_types}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute similarity between words based on their containment patterns\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Normalize\n",
    "word_sim = cosine_similarity(feature_matrix + 1e-10)\n",
    "\n",
    "# Find most similar word pairs\n",
    "similar_pairs = []\n",
    "for i in range(n_words):\n",
    "    for j in range(i+1, n_words):\n",
    "        if word_sim[i, j] > 0.1:\n",
    "            similar_pairs.append((words_with_contexts[i], words_with_contexts[j], word_sim[i, j]))\n",
    "\n",
    "similar_pairs.sort(key=lambda x: -x[2])\n",
    "\n",
    "print(\"Most similar words (by containment pattern):\")\n",
    "print(\"=\" * 50)\n",
    "for w1, w2, sim in similar_pairs[:10]:\n",
    "    print(f\"  '{w1}' ↔ '{w2}': {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-20",
   "metadata": {},
   "source": [
    "Words with similar containment patterns are semantically related. This is the categorical foundation of distributional semantics.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-21",
   "metadata": {},
   "source": [
    "## Part 5: Visualizing the Language Category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-22",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Focus on a subset: the \"stakdur\" context graph\n",
    "stakdur_related = set(['stakdur'])\n",
    "\n",
    "# Add immediate neighbors\n",
    "for phrase in list(stakdur_related):\n",
    "    if phrase in G_lang:\n",
    "        stakdur_related.update(G_lang.successors(phrase))\n",
    "        stakdur_related.update(G_lang.predecessors(phrase))\n",
    "\n",
    "G_stakdur = G_lang.subgraph(stakdur_related).copy()\n",
    "\n",
    "print(f\"Stakdur context subgraph: {G_stakdur.number_of_nodes()} nodes, {G_stakdur.number_of_edges()} edges\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "fig, ax = plt.subplots(figsize=(14, 10))\n",
    "\n",
    "pos = nx.spring_layout(G_stakdur, k=2, iterations=50, seed=42)\n",
    "\n",
    "# Color nodes by type\n",
    "node_colors = ['gold' if node == 'stakdur' else 'lightblue' for node in G_stakdur.nodes()]\n",
    "\n",
    "nx.draw_networkx_nodes(G_stakdur, pos, node_color=node_colors, node_size=2000, ax=ax)\n",
    "nx.draw_networkx_labels(G_stakdur, pos, font_size=9, ax=ax)\n",
    "nx.draw_networkx_edges(G_stakdur, pos, edge_color='gray', arrows=True, \n",
    "                        arrowsize=15, connectionstyle='arc3,rad=0.1', ax=ax)\n",
    "\n",
    "ax.set_title('Language Category: Stakdur Context Graph\\n(Edges = containment)', fontsize=12)\n",
    "ax.axis('off')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-24",
   "metadata": {},
   "source": [
    "The graph shows how \"stakdur\" is embedded in larger linguistic structures. Each edge is a morphism in the language category.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-25",
   "metadata": {},
   "source": [
    "## Part 6: Composition and Transitivity\n",
    "\n",
    "In a category, morphisms compose. In the language category:\n",
    "- If \"stakdur\" ⊆ \"stakdur territory\" and \"stakdur territory\" ⊆ \"the stakdur territory\"\n",
    "- Then \"stakdur\" ⊆ \"the stakdur territory\" (composition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find composition chains (paths of length > 1)\n",
    "def find_composition_chains(G, max_length=3):\n",
    "    \"\"\"Find all paths of length 2+ (composable morphisms).\"\"\"\n",
    "    chains = []\n",
    "    for source in G.nodes():\n",
    "        for target in G.nodes():\n",
    "            if source != target:\n",
    "                # Find all simple paths\n",
    "                try:\n",
    "                    for path in nx.all_simple_paths(G, source, target, cutoff=max_length):\n",
    "                        if len(path) > 2:  # More than just source → target\n",
    "                            chains.append(path)\n",
    "                except nx.NetworkXNoPath:\n",
    "                    pass\n",
    "    return chains\n",
    "\n",
    "# Find chains in the stakdur subgraph\n",
    "chains = find_composition_chains(G_stakdur, max_length=3)\n",
    "\n",
    "print(f\"Found {len(chains)} composition chains:\")\n",
    "print(\"=\" * 50)\n",
    "for chain in chains[:10]:\n",
    "    print(f\"  {' → '.join(chain)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute transitive closure\n",
    "G_closure = nx.transitive_closure(G_lang, reflexive=False)\n",
    "\n",
    "print(f\"Original language category: {G_lang.number_of_edges()} morphisms\")\n",
    "print(f\"Transitive closure: {G_closure.number_of_edges()} morphisms\")\n",
    "print(f\"Implicit morphisms (from composition): {G_closure.number_of_edges() - G_lang.number_of_edges()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "The transitive closure reveals all the implicit containment relationships. These are morphisms that exist through composition.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-29",
   "metadata": {},
   "source": [
    "## Part 7: Context Probability and Meaning\n",
    "\n",
    "The `context_probability` column captures how likely a word is to appear in a given context. This is the foundation of statistical language modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze context probabilities\n",
    "print(\"Context probability statistics:\")\n",
    "print(containment['context_probability'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Which containments have highest probability?\n",
    "high_prob = containment.nlargest(10, 'context_probability')\n",
    "\n",
    "print(\"Highest probability containments:\")\n",
    "print(\"=\" * 50)\n",
    "for _, row in high_prob.iterrows():\n",
    "    print(f\"  '{row['shorter_phrase']}' → '{row['longer_phrase']}' (p={row['context_probability']:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize probability distribution by containment type\n",
    "fig, ax = plt.subplots(figsize=(12, 6))\n",
    "\n",
    "containment.boxplot(column='context_probability', by='containment_type', ax=ax)\n",
    "ax.set_title('Context Probability by Containment Type')\n",
    "ax.set_xlabel('Containment Type')\n",
    "ax.set_ylabel('Context Probability')\n",
    "plt.suptitle('')  # Remove automatic title\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "Different containment types have different probability distributions. Technical terms (Vold's terminology) have high probabilities—they consistently appear together.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Part 8: The ML Connection — Distributional Semantics\n",
    "\n",
    "The categorical view of language directly connects to:\n",
    "\n",
    "### 1. Word2Vec\n",
    "\"Predict a word from its context\" = Learn the containment structure\n",
    "\n",
    "### 2. BERT\n",
    "\"Predict masked words\" = Learn Hom(word, context) relationships\n",
    "\n",
    "### 3. GPT\n",
    "\"Predict next word\" = Learn morphisms in the language category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate word2vec-style \"context prediction\"\n",
    "# Given a word, predict its probable contexts\n",
    "\n",
    "def predict_contexts(word, containment_df, top_k=5):\n",
    "    \"\"\"Predict most likely contexts for a word.\"\"\"\n",
    "    word_data = containment_df[containment_df['shorter_phrase'] == word]\n",
    "    if len(word_data) == 0:\n",
    "        return []\n",
    "    \n",
    "    sorted_data = word_data.sort_values('context_probability', ascending=False)\n",
    "    return list(sorted_data[['longer_phrase', 'context_probability']].head(top_k).itertuples(index=False, name=None))\n",
    "\n",
    "# Test predictions\n",
    "test_words = ['passage', 'stakdur', 'theorem', 'archive']\n",
    "\n",
    "print(\"Context prediction (like word2vec):\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for word in test_words:\n",
    "    predictions = predict_contexts(word, containment)\n",
    "    print(f\"\\n'{word}' → predicted contexts:\")\n",
    "    for context, prob in predictions:\n",
    "        print(f\"    '{context}' (p={prob:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build a simple \"language model\" that predicts containment probability\n",
    "# This is a categorical language model!\n",
    "\n",
    "def categorical_lm_probability(word, context, containment_df):\n",
    "    \"\"\"\n",
    "    P(context | word) in the language category.\n",
    "    Returns the probability if the containment exists, 0 otherwise.\n",
    "    \"\"\"\n",
    "    match = containment_df[\n",
    "        (containment_df['shorter_phrase'] == word) & \n",
    "        (containment_df['longer_phrase'] == context)\n",
    "    ]\n",
    "    if len(match) > 0:\n",
    "        return match['context_probability'].values[0]\n",
    "    return 0.0\n",
    "\n",
    "# Test the categorical LM\n",
    "test_pairs = [\n",
    "    ('passage', 'passage diagram'),\n",
    "    ('passage', 'creature passage'),\n",
    "    ('stakdur', 'the stakdur'),\n",
    "    ('stakdur', 'apex stakdur'),\n",
    "    ('theorem', 'probing theorem')\n",
    "]\n",
    "\n",
    "print(\"Categorical language model probabilities:\")\n",
    "print(\"=\" * 50)\n",
    "for word, context in test_pairs:\n",
    "    prob = categorical_lm_probability(word, context, containment)\n",
    "    print(f\"  P('{context}' | '{word}') = {prob:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "This is a categorical language model: it predicts the probability of a morphism (containment) in the language category.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "## Part 9: From Containment to Meaning\n",
    "\n",
    "Vold's insight: meaning emerges from containment patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cluster words by their containment profiles\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Use the feature matrix we built earlier\n",
    "n_clusters = 4\n",
    "\n",
    "if feature_matrix.sum() > 0:  # Check for non-empty features\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    clusters = kmeans.fit_predict(feature_matrix)\n",
    "    \n",
    "    print(f\"Clustered {len(words_with_contexts)} words into {n_clusters} groups:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        cluster_words = [w for w, c in zip(words_with_contexts, clusters) if c == i]\n",
    "        print(f\"\\nCluster {i}: {cluster_words}\")\n",
    "else:\n",
    "    print(\"Feature matrix is empty; skipping clustering\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze what distinguishes clusters\n",
    "if 'clusters' in dir():\n",
    "    print(\"Cluster characteristics (average probability by containment type):\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    for i in range(n_clusters):\n",
    "        mask = clusters == i\n",
    "        cluster_features = feature_matrix[mask].mean(axis=0)\n",
    "        \n",
    "        print(f\"\\nCluster {i}:\")\n",
    "        top_types = sorted(zip(all_types, cluster_features), key=lambda x: -x[1])[:3]\n",
    "        for ctype, avg in top_types:\n",
    "            if avg > 0:\n",
    "                print(f\"    {ctype}: {avg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-41",
   "metadata": {},
   "source": [
    "Words cluster by their containment patterns. This is semantic clustering emerging from categorical structure—exactly what Vold predicted.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "### Exercise 1: Morphism Chains\n",
    "\n",
    "Find the longest containment chain starting from the word \"form\". What does this reveal about how \"form\" is used in Densworld texts?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Use nx.dag_longest_path or find paths manually"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "### Exercise 2: Context Overlap\n",
    "\n",
    "Find pairs of words that share the same containing phrases. These words may be semantically related."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Compare successor sets in the graph"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-46",
   "metadata": {},
   "source": [
    "### Exercise 3: Probability Prediction\n",
    "\n",
    "Build a simple model that predicts context probability from containment type. Does the type strongly predict the probability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Group by containment_type and compute mean probability"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-48",
   "metadata": {},
   "source": [
    "### Exercise 4: The Vold Vocabulary\n",
    "\n",
    "Vold introduced specific terminology (passage, morphism, coherent shift, etc.). Analyze how her terms cluster compared to everyday Densworld words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Filter for Vold-related terms and compare their embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-50",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Discussion Questions\n",
    "\n",
    "1. Vold claims meaning emerges from containment. But doesn't containment presuppose meaning? Can the categorical approach really ground semantics?\n",
    "\n",
    "2. Modern language models (GPT, etc.) learn statistical patterns over text. Is this fundamentally categorical? What would Vold say about transformer architectures?\n",
    "\n",
    "3. The language category is a pre-order (at most one morphism between any pair). What structure is lost compared to a richer category?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-51",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "| Concept | What You Learned |\n",
    "|---------|------------------|\n",
    "| Language category | Objects = phrases, morphisms = containment |\n",
    "| Pre-order structure | At most one morphism between any pair |\n",
    "| Contextual meaning | Words are defined by what contains them |\n",
    "| Categorical LM | Probability of morphisms as language model |\n",
    "| Distributional semantics | \"Know a word by the company it keeps\" |\n",
    "\n",
    "| Skill | Code Pattern |\n",
    "|-------|--------------|\n",
    "| Build containment graph | `nx.DiGraph()`, add edges for containment |\n",
    "| Find contexts | `G.successors(word)` |\n",
    "| Compute word similarity | Cosine similarity on containment features |\n",
    "| Predict contexts | Sort by probability |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-52",
   "metadata": {},
   "source": [
    "## Next Tutorial\n",
    "\n",
    "In **Tutorial 9: Weighted Passages**, you will learn about **enriched categories**:\n",
    "\n",
    "- Morphisms decorated with values (probabilities, costs, weights)\n",
    "- How enrichment changes categorical reasoning\n",
    "- Connection to weighted graphs and probabilistic models\n",
    "- The categorical foundation of neural attention\n",
    "\n",
    "> *\"A passage is not merely a yes or no. Some passages are likely, others rare. Some paths are well-worn, others barely visible. To capture this, we must enrich our category with degrees of passability.\"*\n",
    "> — Tessery Vold, \"Weighted Passages,\" Year 901\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-53",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "**Source Material:** Tai-Danae Bradley, \"Category Theory and Language Models\" (Cartesian Cafe)\n",
    "\n",
    "**Densworld Integration:** The Relational Foundations course applies categorical concepts through the framework of Tessery Vold.\n",
    "\n",
    "**Learn more:** [buildLittleWorlds](https://github.com/buildLittleWorlds)\n",
    "\n",
    "---\n",
    "\n",
    "> *\"The linguists say: 'You know a word by the company it keeps.' But I say: you know a word by the passages it admits. What phrases contain it? What sentences extend it? The word IS the pattern of its containments. This is not metaphor. This is the mathematics of meaning.\"*\n",
    "> — Tessery Vold, \"The Language of Dens,\" Year 899"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
