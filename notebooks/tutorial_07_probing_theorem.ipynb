{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cell-0",
   "metadata": {},
   "source": [
    "# Tutorial 7: The Probing Theorem\n",
    "## The Yoneda Lemma\n",
    "\n",
    "---\n",
    "\n",
    "### The Crown Jewel\n",
    "\n",
    "*To the research assistant:*\n",
    "\n",
    "*In Year 892, Tessery Vold made her most profound claim. She called it the Probing Theorem:*\n",
    "\n",
    "> *\"Tell me every creature that passes through the stakdur's territory, and I will tell you what a stakdur is—without ever seeing one.\"*\n",
    "\n",
    "*This statement scandalized the Capital's natural philosophers. How can you know what something IS from how other things interact with it? Surely the stakdur has intrinsic properties—teeth, claws, behaviors—that define it independently of its relationships?*\n",
    "\n",
    "*Marden Krell objected: \"This is circular reasoning. To know what passes through the stakdur's territory, you must first know what a stakdur is and where its territory lies.\"*\n",
    "\n",
    "*Vold's response was devastating: \"I observe passages. I do not first define objects. The passages exist. From them, the objects emerge. The circularity you see is only in your ontology—not in mine.\"*\n",
    "\n",
    "*The Probing Theorem is what modern category theorists call the Yoneda Lemma. It is often called the most important result in category theory. Your task: understand why.*\n",
    "\n",
    "—*Archive Review Committee, Year 934*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-1",
   "metadata": {},
   "source": [
    "## What You Will Learn\n",
    "\n",
    "In this tutorial, you will learn to:\n",
    "\n",
    "1. State the **Yoneda Lemma** and understand its components\n",
    "2. See why objects are \"determined\" by their probing patterns\n",
    "3. Understand the **Yoneda embedding** and why it's fully faithful\n",
    "4. Connect the Yoneda Lemma to embeddings and representations in ML\n",
    "5. Implement Yoneda-style reasoning with passage data\n",
    "\n",
    "By the end, you will understand:\n",
    "- Why Nat(Hom(-, X), F) ≅ F(X)\n",
    "- The philosophical implications of \"objects are relationships\"\n",
    "- How word embeddings secretly use Yoneda-style reasoning\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-2",
   "metadata": {},
   "source": [
    "## The Yoneda Lemma Statement\n",
    "\n",
    "For any category C, object X in C, and functor F: C^op → Set:\n",
    "\n",
    "**Nat(Hom(-, X), F) ≅ F(X)**\n",
    "\n",
    "In words:\n",
    "- The set of natural transformations from the probing functor Hom(-, X) to any functor F\n",
    "- Is isomorphic to the set F(X)\n",
    "\n",
    "### What This Means\n",
    "\n",
    "1. **Objects can be recovered from functors**: X ↦ Hom(-, X) is injective (up to isomorphism)\n",
    "2. **Natural transformations are \"probing\"**: Giving a natural transformation η: Hom(-, X) ⇒ F is the same as picking an element of F(X)\n",
    "3. **Representable functors are special**: Hom(-, X) \"represents\" the object X\n",
    "\n",
    "### Vold's Interpretation\n",
    "\n",
    "> *\"The Probing Theorem says: if you know all the coherent ways to shift from the stakdur's probing pattern to any other pattern, you know everything about the stakdur that can be known categorically. The object is not the thing—it is the web of coherent relationships.\"*\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Part 1: Setting Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "from itertools import product\n",
    "\n",
    "# Set style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette('deep')\n",
    "\n",
    "print(\"Libraries loaded. Ready to explore the Probing Theorem.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the passage diagram data\n",
    "BASE_URL = \"https://raw.githubusercontent.com/buildLittleWorlds/densworld-datasets/main/data/\"\n",
    "\n",
    "passages = pd.read_csv(BASE_URL + \"passage_diagrams.csv\")\n",
    "classifications = pd.read_csv(BASE_URL + \"archive_classifications.csv\")\n",
    "\n",
    "print(f\"Passages loaded: {len(passages)} morphisms\")\n",
    "print(f\"Classifications loaded: {len(classifications)} records\")\n",
    "\n",
    "# Get all objects\n",
    "all_objects = sorted(set(passages['source_object']) | set(passages['target_object']))\n",
    "print(f\"Objects in passage category: {len(all_objects)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-6",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Part 2: The Yoneda Embedding\n",
    "\n",
    "The **Yoneda embedding** is the functor:\n",
    "\n",
    "y: C → [C^op, Set]\n",
    "\n",
    "That sends each object X to the functor Hom(-, X).\n",
    "\n",
    "The Yoneda Lemma implies that this embedding is **fully faithful**:\n",
    "- Different objects map to different functors (faithful)\n",
    "- Every morphism between Hom(-, X) and Hom(-, Y) comes from a morphism X → Y (full)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def hom_to(target, passages_df):\n",
    "    \"\"\"\n",
    "    Compute Hom(-, target): morphisms into target.\n",
    "    Returns a dict: source → list of (source, target, morphism_type) tuples.\n",
    "    \"\"\"\n",
    "    incoming = passages_df[passages_df['target_object'] == target]\n",
    "    result = defaultdict(list)\n",
    "    for _, row in incoming.iterrows():\n",
    "        result[row['source_object']].append({\n",
    "            'passage_id': row['passage_id'],\n",
    "            'morphism_type': row['morphism_type']\n",
    "        })\n",
    "    return dict(result)\n",
    "\n",
    "# Compute Hom(-, X) for each object X\n",
    "yoneda_embedding = {obj: hom_to(obj, passages) for obj in all_objects}\n",
    "\n",
    "print(\"Yoneda Embedding: Each object X ↦ Hom(-, X)\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display some examples\n",
    "example_objects = ['stakdur_territory', 'reed_marsh', 'boundary_zone']\n",
    "\n",
    "for obj in example_objects:\n",
    "    hom = yoneda_embedding[obj]\n",
    "    print(f\"\\nHom(-, {obj}):\")\n",
    "    if hom:\n",
    "        for source, morphisms in hom.items():\n",
    "            for m in morphisms:\n",
    "                print(f\"    {source} → {obj} ({m['morphism_type']})\")\n",
    "    else:\n",
    "        print(\"    (no morphisms target this object)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-9",
   "metadata": {},
   "source": [
    "The Yoneda embedding captures each object as a \"pattern of incoming morphisms.\" This is the essence of Vold's Probing Theorem.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Part 3: Faithfulness — Different Objects, Different Functors\n",
    "\n",
    "The Yoneda embedding is faithful: if X ≠ Y (as objects), then Hom(-, X) ≠ Hom(-, Y) (as functors).\n",
    "\n",
    "Let's verify this by comparing probing patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def probing_signature(obj, passages_df):\n",
    "    \"\"\"\n",
    "    Create a signature for Hom(-, obj) that can be compared for equality.\n",
    "    Returns a frozenset of (source, morphism_type) pairs.\n",
    "    \"\"\"\n",
    "    incoming = passages_df[passages_df['target_object'] == obj]\n",
    "    return frozenset((row['source_object'], row['morphism_type']) \n",
    "                      for _, row in incoming.iterrows())\n",
    "\n",
    "# Compute signatures for all objects\n",
    "signatures = {obj: probing_signature(obj, passages) for obj in all_objects}\n",
    "\n",
    "# Check for collisions (different objects with same probing pattern)\n",
    "sig_to_objects = defaultdict(list)\n",
    "for obj, sig in signatures.items():\n",
    "    sig_to_objects[sig].append(obj)\n",
    "\n",
    "print(\"Checking faithfulness of Yoneda embedding:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "collisions = {sig: objs for sig, objs in sig_to_objects.items() if len(objs) > 1}\n",
    "\n",
    "if collisions:\n",
    "    print(f\"\\nFound {len(collisions)} signature collisions:\")\n",
    "    for sig, objs in collisions.items():\n",
    "        print(f\"  Objects with same probing pattern: {objs}\")\n",
    "else:\n",
    "    print(\"\\nNo collisions found: every object has a unique probing pattern.\")\n",
    "    print(\"The Yoneda embedding is faithful on this category.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some objects may have empty probing patterns (nothing targets them)\n",
    "empty_pattern_objects = [obj for obj, sig in signatures.items() if len(sig) == 0]\n",
    "\n",
    "print(f\"\\nObjects with empty probing pattern: {len(empty_pattern_objects)}\")\n",
    "if empty_pattern_objects:\n",
    "    print(\"These are 'initial-like' objects—nothing points to them.\")\n",
    "    print(f\"Examples: {empty_pattern_objects[:5]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-13",
   "metadata": {},
   "source": [
    "Even objects with empty probing patterns are distinguished—they all map to the empty functor, but their *outgoing* morphisms still differ.\n",
    "\n",
    "In a fuller category with identity morphisms for every object, no probing pattern would be truly empty.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-14",
   "metadata": {},
   "source": [
    "## Part 4: The Yoneda Lemma in Action\n",
    "\n",
    "The Yoneda Lemma says:\n",
    "\n",
    "**Nat(Hom(-, X), F) ≅ F(X)**\n",
    "\n",
    "Let's unpack this with a concrete example. We'll take:\n",
    "- X = stakdur_territory\n",
    "- F = the \"morphism count\" functor that counts incoming morphisms\n",
    "\n",
    "F(Y) = |Hom(Y, -)| for some fixed - (we'll use the sum over all targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple functor F: C^op → Set\n",
    "# F(Y) = number of morphisms FROM Y (out-degree)\n",
    "\n",
    "def out_degree_functor(obj, passages_df):\n",
    "    \"\"\"F(obj) = count of outgoing morphisms from obj.\"\"\"\n",
    "    return len(passages_df[passages_df['source_object'] == obj])\n",
    "\n",
    "# Compute F for all objects\n",
    "F = {obj: out_degree_functor(obj, passages) for obj in all_objects}\n",
    "\n",
    "print(\"Functor F: object ↦ out-degree\")\n",
    "print(\"=\" * 40)\n",
    "for obj, count in sorted(F.items(), key=lambda x: -x[1])[:10]:\n",
    "    print(f\"  F({obj}) = {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Yoneda Lemma says:\n",
    "# Nat(Hom(-, X), F) ≅ F(X)\n",
    "\n",
    "# For X = stakdur_territory:\n",
    "X = 'stakdur_territory'\n",
    "\n",
    "print(f\"For X = {X}:\")\n",
    "print(f\"  F(X) = {F[X]}\")\n",
    "print(\"\\n  Yoneda says: the natural transformations Hom(-, X) ⇒ F\")\n",
    "print(f\"  are in bijection with F(X) = {F[X]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# What does a natural transformation η: Hom(-, X) ⇒ F look like?\n",
    "# For each object Y, η_Y: Hom(Y, X) → F(Y)\n",
    "# This maps morphisms Y → X to elements of F(Y) = out-degree of Y\n",
    "\n",
    "print(\"Components of a natural transformation η: Hom(-, X) ⇒ F\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "hom_X = yoneda_embedding[X]\n",
    "\n",
    "for Y in hom_X.keys():\n",
    "    hom_YX = hom_X[Y]  # morphisms from Y to X\n",
    "    F_Y = F[Y]  # out-degree of Y\n",
    "    print(f\"\\n  Y = {Y}\")\n",
    "    print(f\"    Hom({Y}, {X}) has {len(hom_YX)} morphism(s)\")\n",
    "    print(f\"    F({Y}) = {F_Y}\")\n",
    "    print(f\"    η_Y maps {len(hom_YX)} morphism(s) into the set of size {F_Y}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-18",
   "metadata": {},
   "source": [
    "The Yoneda Lemma is saying: instead of specifying all these η_Y components (which must satisfy naturality), you can just pick one element of F(X).\n",
    "\n",
    "This is a remarkable compression: an infinite amount of coherent data reduces to a single choice.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-19",
   "metadata": {},
   "source": [
    "## Part 5: The Bijection Explicitly\n",
    "\n",
    "Let's construct the bijection from the Yoneda Lemma:\n",
    "\n",
    "**Given** a natural transformation η: Hom(-, X) ⇒ F\n",
    "**Get** an element of F(X) by: η_X(id_X)\n",
    "\n",
    "**Given** an element x ∈ F(X)\n",
    "**Get** a natural transformation by: η_Y(f) = F(f)(x) for each morphism f: Y → X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direction 1: Natural transformation → Element of F(X)\n",
    "\n",
    "# The key is: evaluate at the identity morphism id_X: X → X\n",
    "# η_X(id_X) gives an element of F(X)\n",
    "\n",
    "X = 'stakdur_territory'\n",
    "\n",
    "# Check if there's an identity morphism for X in the data\n",
    "identity_X = passages[\n",
    "    (passages['source_object'] == X) & \n",
    "    (passages['target_object'] == X) &\n",
    "    (passages['morphism_type'] == 'identity')\n",
    "]\n",
    "\n",
    "if len(identity_X) > 0:\n",
    "    print(f\"Identity morphism for {X} exists: {identity_X['passage_id'].values[0]}\")\n",
    "    print(f\"\\nTo get an element of F(X) = {F[X]}, evaluate η at this identity.\")\n",
    "    print(\"Since F(X) = out-degree, we're picking one of the outgoing morphisms.\")\n",
    "else:\n",
    "    print(f\"No explicit identity morphism for {X} in data.\")\n",
    "    print(\"(In a proper category, we assume it exists.)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Direction 2: Element of F(X) → Natural transformation\n",
    "\n",
    "# Pick an element of F(X) = out-degree of X\n",
    "# For simplicity, let's say we pick \"the first outgoing morphism\"\n",
    "\n",
    "outgoing_from_X = passages[passages['source_object'] == X]\n",
    "print(f\"Outgoing morphisms from {X}:\")\n",
    "print(outgoing_from_X[['passage_id', 'target_object', 'morphism_type']])\n",
    "\n",
    "print(f\"\\nF({X}) = {len(outgoing_from_X)} (the out-degree)\")\n",
    "print(\"\\nChoosing element x = 'first outgoing morphism' ∈ F(X)\")\n",
    "print(\"This determines a natural transformation η: Hom(-, X) ⇒ F\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-22",
   "metadata": {},
   "source": [
    "The Yoneda bijection is surprisingly simple:\n",
    "- **Forward**: Evaluate η at the identity\n",
    "- **Backward**: Extend by functoriality\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-23",
   "metadata": {},
   "source": [
    "## Part 6: Objects as Representable Functors\n",
    "\n",
    "The Yoneda Lemma has a corollary: the functor Hom(-, X) **represents** the object X.\n",
    "\n",
    "If Hom(-, X) ≅ Hom(-, Y) as functors, then X ≅ Y as objects.\n",
    "\n",
    "This is Vold's claim: **the probing pattern determines the object**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare probing patterns of different objects\n",
    "\n",
    "def compare_probing_patterns(obj1, obj2, passages_df):\n",
    "    \"\"\"Compare Hom(-, obj1) and Hom(-, obj2).\"\"\"\n",
    "    sig1 = probing_signature(obj1, passages_df)\n",
    "    sig2 = probing_signature(obj2, passages_df)\n",
    "    \n",
    "    common = sig1 & sig2\n",
    "    only_1 = sig1 - sig2\n",
    "    only_2 = sig2 - sig1\n",
    "    \n",
    "    return {\n",
    "        'common': common,\n",
    "        'only_obj1': only_1,\n",
    "        'only_obj2': only_2,\n",
    "        'similarity': len(common) / max(len(sig1 | sig2), 1)\n",
    "    }\n",
    "\n",
    "# Compare some objects\n",
    "pairs = [\n",
    "    ('stakdur_territory', 'reed_marsh'),\n",
    "    ('grimslew_pool', 'open_water'),\n",
    "    ('boundary_zone', 'capital_outskirts')\n",
    "]\n",
    "\n",
    "print(\"Comparing probing patterns:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for obj1, obj2 in pairs:\n",
    "    result = compare_probing_patterns(obj1, obj2, passages)\n",
    "    print(f\"\\n{obj1} vs {obj2}:\")\n",
    "    print(f\"  Similarity: {result['similarity']:.2%}\")\n",
    "    print(f\"  Common sources: {len(result['common'])}\")\n",
    "    print(f\"  Unique to {obj1}: {len(result['only_obj1'])}\")\n",
    "    print(f\"  Unique to {obj2}: {len(result['only_obj2'])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize similarity between all objects based on probing patterns\n",
    "\n",
    "# Compute pairwise similarities\n",
    "n = len(all_objects)\n",
    "similarity_matrix = np.zeros((n, n))\n",
    "\n",
    "for i, obj1 in enumerate(all_objects):\n",
    "    for j, obj2 in enumerate(all_objects):\n",
    "        if i == j:\n",
    "            similarity_matrix[i, j] = 1.0\n",
    "        elif i < j:\n",
    "            result = compare_probing_patterns(obj1, obj2, passages)\n",
    "            similarity_matrix[i, j] = result['similarity']\n",
    "            similarity_matrix[j, i] = result['similarity']\n",
    "\n",
    "print(f\"Computed {n}x{n} similarity matrix based on probing patterns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show most similar pairs (excluding identity)\n",
    "similar_pairs = []\n",
    "for i in range(n):\n",
    "    for j in range(i+1, n):\n",
    "        if similarity_matrix[i, j] > 0:\n",
    "            similar_pairs.append((all_objects[i], all_objects[j], similarity_matrix[i, j]))\n",
    "\n",
    "similar_pairs.sort(key=lambda x: -x[2])\n",
    "\n",
    "print(\"Most similar object pairs (by probing pattern):\")\n",
    "print(\"=\" * 50)\n",
    "for obj1, obj2, sim in similar_pairs[:10]:\n",
    "    print(f\"  {obj1} ↔ {obj2}: {sim:.2%}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-27",
   "metadata": {},
   "source": [
    "Objects with similar probing patterns are \"similar\" in a categorical sense. The Yoneda Lemma tells us this is the **correct** notion of similarity for categorical objects.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-28",
   "metadata": {},
   "source": [
    "## Part 7: The ML Connection — Word Embeddings\n",
    "\n",
    "The Yoneda Lemma is secretly behind word embeddings:\n",
    "\n",
    "- **Words** are objects\n",
    "- **Co-occurrence** is morphism-like (\"this word appears near that word\")\n",
    "- **Embeddings** are like Hom(-, X): they capture how other words relate to X\n",
    "\n",
    "John Firth's famous quote:\n",
    "> \"You shall know a word by the company it keeps.\"\n",
    "\n",
    "This IS the Yoneda Lemma for language!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate Yoneda-style embeddings\n",
    "# We'll embed each object as a vector based on what points to it\n",
    "\n",
    "# Create a feature for each possible (source, morphism_type) pair\n",
    "all_morphism_pairs = set()\n",
    "for _, row in passages.iterrows():\n",
    "    all_morphism_pairs.add((row['source_object'], row['morphism_type']))\n",
    "\n",
    "feature_list = sorted(all_morphism_pairs)\n",
    "feature_to_idx = {f: i for i, f in enumerate(feature_list)}\n",
    "\n",
    "print(f\"Feature space dimension: {len(feature_list)}\")\n",
    "print(f\"Each object will be embedded as a {len(feature_list)}-dimensional vector\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Yoneda embeddings\n",
    "yoneda_vectors = np.zeros((len(all_objects), len(feature_list)))\n",
    "\n",
    "for i, obj in enumerate(all_objects):\n",
    "    sig = probing_signature(obj, passages)\n",
    "    for pair in sig:\n",
    "        if pair in feature_to_idx:\n",
    "            yoneda_vectors[i, feature_to_idx[pair]] = 1\n",
    "\n",
    "print(f\"Yoneda embedding matrix: {yoneda_vectors.shape}\")\n",
    "print(f\"Sparsity: {1 - np.count_nonzero(yoneda_vectors) / yoneda_vectors.size:.2%}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between Yoneda embeddings\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Add small epsilon to avoid division by zero\n",
    "yoneda_sim = cosine_similarity(yoneda_vectors + 1e-10)\n",
    "\n",
    "print(\"Cosine similarity based on Yoneda embeddings:\")\n",
    "print(\"=\" * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find most similar pairs\n",
    "yoneda_pairs = []\n",
    "for i in range(len(all_objects)):\n",
    "    for j in range(i+1, len(all_objects)):\n",
    "        if yoneda_sim[i, j] > 0.01:  # Skip near-zero\n",
    "            yoneda_pairs.append((all_objects[i], all_objects[j], yoneda_sim[i, j]))\n",
    "\n",
    "yoneda_pairs.sort(key=lambda x: -x[2])\n",
    "\n",
    "print(\"Most similar objects (Yoneda embedding):\")\n",
    "for obj1, obj2, sim in yoneda_pairs[:10]:\n",
    "    print(f\"  {obj1} ↔ {obj2}: {sim:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-33",
   "metadata": {},
   "source": [
    "This is exactly how word embeddings work:\n",
    "1. Represent each word by its context (what words appear near it)\n",
    "2. Similar contexts → similar embeddings\n",
    "3. The embedding \"knows\" the word by the company it keeps\n",
    "\n",
    "The Yoneda Lemma provides the theoretical foundation.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-34",
   "metadata": {},
   "source": [
    "## Part 8: Dimensionality Reduction of Yoneda Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use PCA to reduce Yoneda embeddings to 2D for visualization\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Only include objects with non-zero embeddings\n",
    "non_zero_mask = yoneda_vectors.sum(axis=1) > 0\n",
    "active_objects = [obj for obj, mask in zip(all_objects, non_zero_mask) if mask]\n",
    "active_vectors = yoneda_vectors[non_zero_mask]\n",
    "\n",
    "if len(active_objects) >= 2:\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced = pca.fit_transform(active_vectors)\n",
    "    \n",
    "    print(f\"Reduced {len(active_objects)} objects to 2D\")\n",
    "    print(f\"Variance explained: {pca.explained_variance_ratio_.sum():.2%}\")\n",
    "else:\n",
    "    print(\"Not enough non-zero embeddings for PCA\")\n",
    "    reduced = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize Yoneda embeddings in 2D\n",
    "if reduced is not None and len(reduced) > 0:\n",
    "    fig, ax = plt.subplots(figsize=(14, 10))\n",
    "    \n",
    "    ax.scatter(reduced[:, 0], reduced[:, 1], s=100, alpha=0.6, c='steelblue')\n",
    "    \n",
    "    for i, obj in enumerate(active_objects):\n",
    "        ax.annotate(obj, (reduced[i, 0], reduced[i, 1]), fontsize=8, alpha=0.8)\n",
    "    \n",
    "    ax.set_xlabel('PC1')\n",
    "    ax.set_ylabel('PC2')\n",
    "    ax.set_title('Yoneda Embeddings (PCA)\\nObjects as \"How They\\'re Probed\"', fontsize=12)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Visualization not available\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-37",
   "metadata": {},
   "source": [
    "Objects that cluster together have similar probing patterns. This is the Yoneda perspective: similarity IS similarity of probing patterns.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-38",
   "metadata": {},
   "source": [
    "## Part 9: Philosophical Implications\n",
    "\n",
    "The Yoneda Lemma has profound philosophical implications:\n",
    "\n",
    "### 1. Anti-Essentialism\n",
    "Objects don't have \"intrinsic essences.\" They are what they do—how they relate to everything else.\n",
    "\n",
    "### 2. Holism\n",
    "You can't understand an object in isolation. Its identity depends on the entire network of relationships.\n",
    "\n",
    "### 3. Structuralism\n",
    "Structure is more fundamental than substance. The \"what\" is determined by the \"how.\"\n",
    "\n",
    "### Vold's Claim\n",
    "> *\"Marden Krell asked: what is the stakdur before we observe its passages? I say: that question has no answer. Before passages, there is no stakdur. The stakdur emerges from the pattern of passages. It does not precede them.\"*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final demonstration: reconstructing object identity from probing\n",
    "\n",
    "def identify_from_probing(signature, signatures_dict):\n",
    "    \"\"\"Given a probing signature, find the object.\"\"\"\n",
    "    matches = [obj for obj, sig in signatures_dict.items() if sig == signature]\n",
    "    return matches\n",
    "\n",
    "# Test: can we identify stakdur_territory from its probing pattern alone?\n",
    "test_obj = 'stakdur_territory'\n",
    "test_sig = signatures[test_obj]\n",
    "\n",
    "identified = identify_from_probing(test_sig, signatures)\n",
    "\n",
    "print(\"The Probing Theorem in action:\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nGiven probing signature: {dict(list(test_sig)[:3])}...\")\n",
    "print(f\"Identified object(s): {identified}\")\n",
    "print(f\"\\nVold: 'I told you what the stakdur is—without ever seeing one.'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-40",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Exercises\n",
    "\n",
    "### Exercise 1: Dual Yoneda\n",
    "\n",
    "The Yoneda embedding uses Hom(-, X) (incoming morphisms). Build the dual using Hom(X, -) (outgoing morphisms). Are objects still distinguishable?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Filter passages by source_object instead of target_object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-42",
   "metadata": {},
   "source": [
    "### Exercise 2: Morphism Types as Features\n",
    "\n",
    "Modify the Yoneda embedding to use morphism types as additional features. Does this improve object distinguishability?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Include (source, type) pairs instead of just sources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-44",
   "metadata": {},
   "source": [
    "### Exercise 3: Lifecycle Objects\n",
    "\n",
    "Focus on lifecycle-related objects (egg, juvenile, adult stages). What do their Yoneda embeddings reveal about lifecycle structure?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Filter to lifecycle_passage morphisms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-46",
   "metadata": {},
   "source": [
    "### Exercise 4: The Identity Element\n",
    "\n",
    "The Yoneda bijection uses the identity morphism. For objects with explicit identities in the data, verify that the bijection works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here\n",
    "# Hint: Find identity morphisms in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-48",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Discussion Questions\n",
    "\n",
    "1. Krell objected that Vold's approach is circular: to know passages, you must first know objects. Vold countered that passages can be observed directly. Who is right? Is observation itself theory-laden?\n",
    "\n",
    "2. The Yoneda Lemma suggests that objects \"are\" their relationships. Does this mean objects are social constructs? What does it mean for scientific realism?\n",
    "\n",
    "3. Word embeddings based on co-occurrence have been remarkably successful. Is this because language is fundamentally categorical, or is it a useful approximation?\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-49",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this tutorial, you learned:\n",
    "\n",
    "| Concept | What You Learned |\n",
    "|---------|------------------|\n",
    "| Yoneda Lemma | Nat(Hom(-, X), F) ≅ F(X) |\n",
    "| Yoneda embedding | X ↦ Hom(-, X) is fully faithful |\n",
    "| Objects as patterns | X is determined by how it's probed |\n",
    "| The bijection | Evaluate at identity ↔ Extend by functoriality |\n",
    "| ML connection | Word embeddings use Yoneda-style reasoning |\n",
    "\n",
    "| Skill | Code Pattern |\n",
    "|-------|--------------|\n",
    "| Compute Hom(-, X) | Filter passages by target_object |\n",
    "| Build Yoneda embedding | Binary feature vector of incoming morphisms |\n",
    "| Compare objects | Cosine similarity of embeddings |\n",
    "| Identify from signature | Match probing patterns |\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-50",
   "metadata": {},
   "source": [
    "## Next Tutorial\n",
    "\n",
    "In **Tutorial 8: The Language of Dens**, you will learn how language itself forms a category:\n",
    "\n",
    "- Words and phrases as objects\n",
    "- Substring containment as morphisms\n",
    "- Language categories and their structure\n",
    "- Connection to distributional semantics\n",
    "\n",
    "> *\"The linguists say: 'You know a word by the company it keeps.' But I say: you know a word by the passages it admits. What phrases contain it? What sentences extend it? The word IS the pattern of its containments.\"*\n",
    "> — Tessery Vold, \"The Language of Dens,\" Year 899\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-51",
   "metadata": {},
   "source": [
    "## Credits\n",
    "\n",
    "**Source Material:** Tai-Danae Bradley, \"Category Theory and Language Models\" (Cartesian Cafe)\n",
    "\n",
    "**Densworld Integration:** The Relational Foundations course applies categorical concepts through the framework of Tessery Vold.\n",
    "\n",
    "**Learn more:** [buildLittleWorlds](https://github.com/buildLittleWorlds)\n",
    "\n",
    "---\n",
    "\n",
    "> *\"Tell me every creature that passes through the stakdur's territory, and I will tell you what a stakdur is—without ever seeing one. This is not mysticism. This is mathematics. The object IS the pattern of passages to it. The Probing Theorem is the foundation of all relational knowledge.\"*\n",
    "> — Tessery Vold, \"The Probing Theorem,\" Year 892"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
